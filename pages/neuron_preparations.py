import streamlit as st
import pandas as pd


class neuron_prepare_viewset:
    def __init__(self):
        pass

    def app(self):
        st.session_state.current_page = "Neuron Preparations"
        st.title("Neural Network Preparations")
        st.markdown("---")
        menu = st.tabs(
            [
                "üåê‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
                "üó≥Ô∏è‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model CNN",
                "üß†‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î CNN Model ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô",
            ]
        )
        with menu[0]:
            self.dataset_preparation()
        with menu[1]:
            self.cnn_model_training()
        with menu[2]:
            self.load_model()
        st.markdown("---")

    def dataset_preparation(self):
        st.header("üîç Data Preparation")
        st.markdown(
            """
            ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô CNN models ‡∏ú‡∏°‡πÑ‡∏î‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ datasets ‡πÉ‡∏ô [<span style='color:blue; text-decoration:none'>Kaggle</span>](https://www.kaggle.com/) ‡πÅ‡∏•‡∏∞‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            "[<span style='color:orange; text-decoration:none; font-weight:bold'>Fruit Classification dataset</span>](https://www.kaggle.com/datasets/karimabdulnabi/fruit-classification10-class/data)"
            ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡πÑ‡∏°‡πâ 10 ‡∏ä‡∏ô‡∏¥‡∏î ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡∏°‡∏≤‡∏ó‡∏≥ Image Classification ‡∏î‡πâ‡∏ß‡∏¢ CNN
            """,
            unsafe_allow_html=True,
        )
        with st.expander("üìä ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Dataset Details)"):
            col1, col2 = st.columns(2)
            with col1:
                st.write("**‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤:** Kaggle Dataset")
                st.write("**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:** 4,323 ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û")
            with col2:
                st.write("**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™:** 10 ‡∏ä‡∏ô‡∏¥‡∏î‡∏ú‡∏•‡πÑ‡∏°‡πâ")
                st.write("**‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û:** ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ç‡∏ô‡∏≤‡∏î (‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)")

        st.header("ü§ñ Model Selection")
        st.markdown(
            "‡∏ú‡∏°‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• **Convolutional Neural Network (CNN)** ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô Image Classification"
        )

        st.header("üìã ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î Features Fruit Classification")

        fruit_data = {
            "‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡πÑ‡∏°‡πâ": [
                "Apple (‡πÅ‡∏≠‡∏õ‡πÄ‡∏õ‡∏¥‡∏•)",
                "Banana (‡∏Å‡∏•‡πâ‡∏ß‡∏¢)",
                "Orange (‡∏™‡πâ‡∏°)",
                "Strawberry (‡∏™‡∏ï‡∏£‡∏≠‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏£‡∏µ‡πà)",
                "Watermelon (‡πÅ‡∏ï‡∏á‡πÇ‡∏°)",
                "Pineapple (‡∏™‡∏±‡∏ö‡∏õ‡∏∞‡∏£‡∏î)",
                "Mango (‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á)",
                "Grape (‡∏≠‡∏á‡∏∏‡πà‡∏ô)",
                "Kiwi (‡∏Å‡∏µ‡∏ß‡∏µ‡πà)",
                "Peach (‡∏û‡∏µ‡∏ä)",
            ],
            "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏π‡∏õ": [
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
            ],
            "‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå": [
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
            ],
        }

        df_fruits = pd.DataFrame(fruit_data)
        st.dataframe(df_fruits, use_container_width=True, height=400)

        st.info("""
        **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** 
        * ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏∏‡∏î‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô folder train ‡πÅ‡∏•‡∏∞ test
        * ‡πÅ‡∏ï‡πà‡∏•‡∏∞ folder ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡πÑ‡∏°‡πâ (Class)
        * ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏Ç‡∏ô‡∏≤‡∏î, ‡∏™‡∏µ, ‡πÅ‡∏•‡∏∞‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á
        * ‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏ó‡∏£‡∏ô‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ú‡∏•‡πÑ‡∏°‡πâ
        """)

        st.header("‚öôÔ∏è ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Preparation Process) ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Model")

        code_tabs = st.tabs(
            ["1Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Libraries", "2Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û", "3Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Model"]
        )
        with code_tabs[0]:
            st.write("Import library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
            st.code("""
                    import numpy as np
                    import matplotlib.pyplot as plt
                    import os
                    import tensorflow as tf
                    from keras.layers import (
                        Dropout,
                        Dense,
                        BatchNormalization,
                        GlobalAveragePooling2D,
                    )
                    from keras.applications import MobileNetV2
                    from keras.models import Sequential
                    from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
                    from keras.callbacks import EarlyStopping, ReduceLROnPlateau
                    """)
        with code_tabs[1]:
            st.write(
                "‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö data ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ train,test,validate ‡πÅ‡∏•‡∏∞ show ‡∏£‡∏π‡∏õ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"
            )
            st.code("""
                    dataset_dir = "../data/fruit/MY_data"
                    train_path = os.path.join(dataset_dir, "train")
                    test_path = os.path.join(dataset_dir, "test")
                    img = load_img(train_path + "/Apple/img_01.jpeg")
                    plt.imshow(img)
                    plt.axis("on")
                    plt.show()
                    img = img_to_array(img)
                    img.shape
                    """)
            st.write(
                "‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î scale ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ model ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ label ‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥ (corrupted data)"
            )
            st.code("""
                    train_datagen = ImageDataGenerator(
                        rescale=1.0 / 255,
                        rotation_range=30,
                        width_shift_range=0.2,
                        height_shift_range=0.2,
                        horizontal_flip=True,
                        zoom_range=0.2,
                        shear_range=0.2,
                        validation_split=0.2,
                    )
                    test_datagen = ImageDataGenerator(rescale=1.0 / 255)
                    """)
            st.markdown("---")
            st.write(
                "‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏î‡∏¢‡πÅ‡∏ö‡πà‡∏á 20% ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö validation ‡∏à‡∏≤‡∏Å path ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ"
            )
            st.info("""
                    * Keras ‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å features ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏±‡∏ô‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ï‡∏≤‡∏°‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
                    * ‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Visualization ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Debug missmatch label ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
                    * ‡∏Å‡∏≥‡∏´‡∏ô‡∏î batch_size (‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏ö‡πà‡∏á‡πÑ‡∏õ‡πÄ‡∏ó‡∏£‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ neuron ‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà 32)
                    """)
            st.code("""
                train_generator = train_datagen.flow_from_directory(
                train_path,
                target_size=(224, 224),
                batch_size=32,
                color_mode="rgb",
                class_mode="categorical",
                subset="training",
            )
            test_generator = test_datagen.flow_from_directory(
                test_path,
                target_size=(224, 224),
                batch_size=32,
                color_mode="rgb",
                class_mode="categorical",
            )
            val_generator = train_datagen.flow_from_directory(
                train_path,
                target_size=(224, 224),
                batch_size=32,
                color_mode="rgb",
                class_mode="categorical",
                subset="validation",
            )
            def visualize_dataset_samples(generator, num_samples=4, class_names=None):

                if class_names is None:
                    class_names = list(generator.class_indices.keys())
                
                x_batch, y_batch = next(generator)
                
                n_classes = len(class_names)
                fig, axes = plt.subplots(n_classes, num_samples, figsize=(num_samples * 3, n_classes * 3))
                
                for i, class_name in enumerate(class_names):
                    class_idx = generator.class_indices[class_name]
                    class_samples = []
                    
                    for j in range(len(y_batch)):
                        if np.argmax(y_batch[j]) == class_idx:
                            class_samples.append(x_batch[j])
                            if len(class_samples) >= num_samples:
                                break
                    
                    while len(class_samples) < num_samples:
                        x_batch, y_batch = next(generator)
                        for j in range(len(y_batch)):
                            if np.argmax(y_batch[j]) == class_idx:
                                class_samples.append(x_batch[j])
                                if len(class_samples) >= num_samples:
                                    break
                    
                    # Plot the samples
                    for j in range(num_samples):
                        ax = axes[i, j] if n_classes > 1 else axes[j]
                        ax.imshow(class_samples[j])
                        ax.set_title(class_name)
                        ax.axis('off')
                
                plt.tight_layout()
                plt.suptitle("Random Samples from Each Class", y=1.02)
                plt.show()
                visualize_dataset_samples(train_generator)
                """)
        with code_tabs[2]:
            st.write(
                "‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Model ‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà‡∏ú‡∏°‡∏à‡∏∞‡πÉ‡∏ä‡πâ base model ‡πÄ‡∏õ‡πá‡∏ô MobileNetV2 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô"
            )
            st.code("""
                    baseModel = MobileNetV2(
                        weights="imagenet", include_top=False, input_shape=(224, 224, 3)
                        )
                    baseModel.trainable = False #‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡πà‡∏≤ weight ‡∏Ç‡∏≠‡∏á MobileNetV2 ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á train
                    """)
            st.markdown("---")
            st.write(
                "‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Model ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Train ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Pooling ‡∏à‡∏≤‡∏Å Keras,‡πÄ‡∏û‡∏¥‡πà‡∏° regularizer ‡πÅ‡∏•‡∏∞ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î lr \n‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ model overfigting"
            )
            st.code("""
                    model = Sequential(
                    [
                        baseModel,
                        GlobalAveragePooling2D(),
                        Dense(
                            128, activation="relu", kernel_regularizer=tf.keras.regularizers.l2(0.0001)
                        ),
                        BatchNormalization(),
                        Dropout(0.3),
                        Dense(
                            64, activation="relu", kernel_regularizer=tf.keras.regularizers.l2(0.0001)
                        ),
                        BatchNormalization(),
                        Dropout(0.3),
                        Dense(
                            32, activation="relu", kernel_regularizer=tf.keras.regularizers.l2(0.0001)
                        ),
                        Dense(10, activation="softmax"),
                    ]
                    )
                    model.summary()
                    model.compile(
                        loss="categorical_crossentropy",
                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
                        metrics=["accuracy"],
                    )
                    """)
            st.subheader("üéâüéâüéâ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Model")
            st.markdown("---")

    def cnn_model_training(self):
        st.header("‚öôÔ∏è ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model CNN (MobileNetV2 base model)")
        st.write(
            "‡∏ú‡∏°‡∏à‡∏∞‡πÉ‡∏ä‡πâ EarlyStopping ‡∏Å‡∏±‡∏ö ReduceLROnPlateau ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà Model ‡πÅ‡∏¢‡πà‡∏•‡∏á"
        )
        st.code("""
                    early_stopping = EarlyStopping(
                        monitor="val_loss", patience=10, restore_best_weights=True, verbose=1
                    )

                    reduce_lr = ReduceLROnPlateau(
                        monitor="val_loss", factor=0.2, patience=3, min_lr=1e-6, verbose=1
                    )
                    """)
        st.write("‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model")
        st.code("""
                    history = model.fit(
                    train_generator,
                    epochs=30,
                    validation_data=val_generator,
                    callbacks=[early_stopping, reduce_lr],
                    )""")

        st.write("Save ‡∏ï‡∏±‡∏ß model ‡πÅ‡∏•‡∏∞ weight ‡πÅ‡∏•‡∏∞ evalute model")
        st.code("""
                    model.save("../exported_models/fruit_model.keras")
                    model.save_weights("../exported_models/fruit_model_weights.h5")
                    model.summary()
                    test_loss, test_acc = model.evaluate(test_generator)
                    print(f"Test accuracy: {test_acc:.4f}")
                    """)
        st.subheader("üéâüéâüéâ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model")

    def load_model(self):
        st.header("‚öôÔ∏è ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Model CNN (MobileNetV2 base model)")
        st.info("""
                    * ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ú‡∏°‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏±‡πâ‡∏á Model ‡πÑ‡∏î‡πâ‡∏à‡∏∂‡∏á‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á architecture ‡∏Ç‡∏≠‡∏á model ‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß‡πÇ‡∏´‡∏•‡∏î weight ‡πÅ‡∏ó‡∏ô
                    """)
        code_tabs_cnn = st.tabs(
            ["1Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Architectire ‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏õ Streamlit", "2Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Model"]
        )
        with code_tabs_cnn[0]:
            st.write("‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Architecture ‡∏Ç‡∏≠‡∏á Model ‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤")
            st.code("""
                    def create_model():
                        baseModel = MobileNetV2(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
                        baseModel.trainable = False
                        model = Sequential([
                            baseModel,
                            GlobalAveragePooling2D(),
                            Dense(128, activation="relu", kernel_regularizer=tf.keras.regularizers.l2(0.0001)),
                            BatchNormalization(),
                            Dropout(0.3),
                            Dense(64, activation="relu", kernel_regularizer=tf.keras.regularizers.l2(0.0001)),
                            BatchNormalization(),
                            Dropout(0.3),
                            Dense(32, activation="relu", kernel_regularizer=tf.keras.regularizers.l2(0.0001)),
                            Dense(10, activation="softmax"),
                        ])
                        
                        model.compile(
                            loss="categorical_crossentropy",
                            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
                            metrics=["accuracy"],
                        )
                        return model""")
            st.warning("""
                            * ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏ß‡πâ‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô
                            """)
        with code_tabs_cnn[1]:
            st.write(
                "‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î model ‡∏ó‡∏±‡πâ‡∏á model ‡∏ú‡∏°‡πÄ‡∏à‡∏≠‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Conv1 error ‡∏à‡∏∂‡∏á‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÉ‡∏™‡πà fallback ‡πÄ‡∏û‡∏∑‡πà‡∏≠ load weight ‡πÅ‡∏ó‡∏ô"
            )
            st.code("""
                        def load_cached_model(model_path, weights_path, img_height, img_width):
                            try:
                                if os.path.exists(model_path):
                                    try:
                                        model = tf.keras.models.load_model(model_path) #‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏±‡πâ‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
                                        print(f"Successfully loaded entire model from {model_path}")
                                        return model, True, f"Successfully loaded entire model from {model_path}"
                                        
                                    except Exception as e:
                                        if "Conv1" in str(e):
                                            print(f"Error loading full model: {e}. Attempting to load weights only.")
                                            if os.path.exists(weights_path):
                                                model = create_model() #‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏™‡∏£‡πâ‡∏≤‡∏á architecture ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢ load weight ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏≤
                                                model.load_weights(weights_path)
                                                print(f"Successfully loaded weights from {weights_path}")
                                    
                                                return model, True, f"Successfully loaded weights from {weights_path}"
                                            else:
                                                return None, False, f"Weights file not found at {weights_path}"
                                        else:
                                            raise e
                                else:
                                    print(f"Model not found at {model_path}")
                                    
                                    # Try loading weights only
                                    if os.path.exists(weights_path):
                                        model = create_model()
                                        model.load_weights(weights_path)
                                        print(f"Loaded weights-only from {weights_path}")
                                        
                                        # Warmup prediction
                                        dummy_input = np.zeros((1, img_height, img_width, 3))
                                        _ = model.predict(dummy_input)
                                        
                                        return model, True, f"Successfully loaded weights-only from {weights_path}"
                                    else:
                                        return None, False, "Neither model nor weights found. Please check the paths."

                            except Exception as e:
                                error_message = f"Error loading model: {e}"
                                print(error_message)
                                return None, False, error_message
                         """)
            st.subheader("üéâüéâüéâ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£ save ‡πÅ‡∏•‡∏∞ load model")
