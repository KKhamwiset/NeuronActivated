import streamlit as st
import pandas as pd


class neuron_prepare_viewset:
    def __init__(self):
        pass

    def app(self):
        st.session_state.current_page = "Neuron Preparations"
        st.title("Neural Network Preparations")
        st.markdown("---")
        menu = st.tabs(
            [
                "üåê‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
                "üó≥Ô∏è‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model CNN",
                "üß†‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î CNN Model ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô",
            ]
        )
        with menu[0]:
            self.dataset_preparation()
        with menu[1]:
            self.cnn_model_training()
            st.markdown("""---""")
        with menu[2]:
            self.load_model()

    def dataset_preparation(self):
        st.header("üîç Data Preparation")
        st.markdown(
            """
            ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô CNN models ‡∏ú‡∏°‡πÑ‡∏î‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ datasets ‡πÉ‡∏ô [<span style='color:blue; text-decoration:none'>Kaggle</span>](https://www.kaggle.com/) ‡πÅ‡∏•‡∏∞‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            "[<span style='color:orange; text-decoration:none; font-weight:bold'>Fruit Classification dataset</span>](https://www.kaggle.com/datasets/karimabdulnabi/fruit-classification10-class/data)"
            ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡πÑ‡∏°‡πâ 10 ‡∏ä‡∏ô‡∏¥‡∏î ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡∏°‡∏≤‡∏ó‡∏≥ Image Classification ‡∏î‡πâ‡∏ß‡∏¢ CNN
            """,
            unsafe_allow_html=True,
        )
        with st.expander("üìä ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Dataset Details)"):
            col1, col2 = st.columns(2)
            with col1:
                st.write("**‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤:** Kaggle Dataset")
                st.write("**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:** 4,323 ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û")
            with col2:
                st.write("**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™:** 10 ‡∏ä‡∏ô‡∏¥‡∏î‡∏ú‡∏•‡πÑ‡∏°‡πâ")
                st.write("**‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û:** ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ç‡∏ô‡∏≤‡∏î (‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)")

        st.header("ü§ñ Model Selection")
        st.markdown(
            "‡∏ú‡∏°‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• **Convolutional Neural Network (CNN)** ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô Image Classification"
        )

        st.header("üìã ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î Features Fruit Classification")

        fruit_data = {
            "‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡πÑ‡∏°‡πâ": [
                "Apple (‡πÅ‡∏≠‡∏õ‡πÄ‡∏õ‡∏¥‡∏•)",
                "Banana (‡∏Å‡∏•‡πâ‡∏ß‡∏¢)",
                "Orange (‡∏™‡πâ‡∏°)",
                "Strawberry (‡∏™‡∏ï‡∏£‡∏≠‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏£‡∏µ‡πà)",
                "Watermelon (‡πÅ‡∏ï‡∏á‡πÇ‡∏°)",
                "Pineapple (‡∏™‡∏±‡∏ö‡∏õ‡∏∞‡∏£‡∏î)",
                "Mango (‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á)",
                "Grape (‡∏≠‡∏á‡∏∏‡πà‡∏ô)",
                "Kiwi (‡∏Å‡∏µ‡∏ß‡∏µ‡πà)",
                "Peach (‡∏û‡∏µ‡∏ä)",
            ],
            "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏π‡∏õ": [
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
                "~430 ‡∏£‡∏π‡∏õ",
            ],
            "‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå": [
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
                "JPG/JPEG",
            ],
        }

        df_fruits = pd.DataFrame(fruit_data)
        st.dataframe(df_fruits, use_container_width=True, height=400)

        st.info("""
        **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** 
        * ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏∏‡∏î‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô folder train ‡πÅ‡∏•‡∏∞ test
        * ‡πÅ‡∏ï‡πà‡∏•‡∏∞ folder ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡πÑ‡∏°‡πâ (Class)
        * ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏Ç‡∏ô‡∏≤‡∏î, ‡∏™‡∏µ, ‡πÅ‡∏•‡∏∞‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á
        * ‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏ó‡∏£‡∏ô‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ú‡∏•‡πÑ‡∏°‡πâ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
        """)

        st.header("‚öôÔ∏è ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Preparation Process)")

        code_tabs = st.tabs(
            ["1Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Libraries", "2Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏ß‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "3Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û"]
        )
        st.markdown(
            """
        <style>
            .stTabs [data-baseweb="tab"] {
                font-size: 28px; 
                font-weight: bold;
            }
            
            .stTabs [data-baseweb="tab-list"] {
                gap: 1.5rem;
            }
        </style>
        """,
            unsafe_allow_html=True,
        )
        with code_tabs[0]:
            st.code(
                """
                import numpy as np
                import pandas as pd
                import matplotlib.pyplot as plt
                import seaborn as sns
                import os
                import tensorflow as tf
                from tensorflow.keras.models import Sequential
                from tensorflow.keras.layers import Dense, MaxPooling2D, Activation, Flatten, Dropout, Conv2D
                from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
                """
            )

        with code_tabs[1]:
            st.code("""
                # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Path ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                dataset_dir = "../data/fruit/MY_data"
                train_path = os.path.join(dataset_dir, "train")
                test_path = os.path.join(dataset_dir, "test")

                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Class ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                classes = os.listdir(train_path)
                print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Class ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(classes)}")
                print(f"‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ Class: {classes}")

                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Class (folder)
                for cls in classes:
                    cls_path = os.path.join(train_path, cls)
                    num_images = len(os.listdir(cls_path))
                    print(f"Class {cls}: {num_images} ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û")

                # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
                img = load_img(train_path + "/Apple/img_01.jpeg")
                plt.imshow(img)
                plt.axis("on")
                plt.show()

                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
                img = img_to_array(img)
                print(f"‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û: {img.shape}")
                """)

        with code_tabs[2]:
            st.code("""
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á Data Generator ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (Data Augmentation)
                train_datagen = ImageDataGenerator(
                    rescale=1./255,         # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 0-1
                    shear_range=0.3,        # ‡∏Å‡∏≤‡∏£‡∏ö‡∏¥‡∏î‡∏†‡∏≤‡∏û
                    horizontal_flip=True,    # ‡∏Å‡∏≤‡∏£‡∏û‡∏•‡∏¥‡∏Å‡∏†‡∏≤‡∏û‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô
                    vertical_flip=False,     # ‡πÑ‡∏°‡πà‡∏û‡∏•‡∏¥‡∏Å‡∏†‡∏≤‡∏û‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á
                    zoom_range=0.3          # ‡∏Å‡∏≤‡∏£‡∏ã‡∏π‡∏°‡∏†‡∏≤‡∏û
                )

                test_datagen = ImageDataGenerator(rescale=1./255)  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô

                # ‡∏™‡∏£‡πâ‡∏≤‡∏á Data Generator ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å directory
                train_generator = train_datagen.flow_from_directory(
                    train_path,
                    target_size=(img.shape[0], img.shape[1]),  # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                    batch_size=32,
                    color_mode='rgb',
                    class_mode='categorical'  # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á Class ‡πÄ‡∏õ‡πá‡∏ô one-hot encoding
                )

                test_generator = test_datagen.flow_from_directory(
                    test_path,
                    target_size=(img.shape[0], img.shape[1]),
                    batch_size=32,
                    color_mode='rgb',
                    class_mode='categorical'
                )

                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å generator
                print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô batch ‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å: {len(train_generator)}")
                print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô batch ‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö: {len(test_generator)}")
                print(f"‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• X: {train_generator.next()[0].shape}")
                print(f"‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• y: {train_generator.next()[1].shape}")
                """)

        second_code_tabs = st.tabs(
            [
                "4Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£ Augmentation",
                "5Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô",
                "6Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN",
            ]
        )

        with second_code_tabs[0]:
            st.code("""
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£ augment ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 5 ‡∏£‡∏π‡∏õ
                fig, axes = plt.subplots(1, 5, figsize=(20, 5))
                for i, (x_batch, y_batch) in enumerate(train_generator):
                    if i >= 5:
                        break
                    axes[i].imshow(x_batch[0])
                    axes[i].set_title(f"Sample {i+1}")
                    axes[i].axis('off')
                plt.tight_layout()
                plt.show()
            """)

        with second_code_tabs[1]:
            st.code("""
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                class_indices = train_generator.class_indices
                print("Class Indices:", class_indices)

                # ‡∏™‡∏•‡∏±‡∏ö key ‡∏Å‡∏±‡∏ö value ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡πÑ‡∏°‡πâ‡πÑ‡∏î‡πâ
                class_names = {v: k for k, v in class_indices.items()}
                print("Class Names:", class_names)

                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™
                class_counts = np.bincount(train_generator.classes)
                for class_id, count in enumerate(class_counts):
                    print(f"Class {class_names[class_id]}: {count} samples")
            """)

        with second_code_tabs[2]:
            st.code("""
                # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN
                model = Sequential([
                    # ‡∏ä‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 1: Convolutional Layer
                    Conv2D(128, 3, activation="relu", input_shape=(img.shape[0], img.shape[1], 3)),
                    MaxPooling2D(2, 2),
                    
                    # ‡∏ä‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 2: Convolutional Layer
                    Conv2D(64, 3, activation="relu"),
                    
                    # ‡∏ä‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 3: Convolutional Layer
                    Conv2D(32, 3, activation="relu"),
                    MaxPooling2D(2, 2),
                    
                    # Dropout ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô overfitting
                    Dropout(0.5),
                    
                    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô 1 ‡∏°‡∏¥‡∏ï‡∏¥
                    Flatten(),
                    
                    # Fully connected layers
                    Dense(256, activation="relu"),
                    Dense(16, activation="relu"),
                    
                    # Output layer (10 classes)
                    Dense(10, activation="softmax")
                ])

                # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
                model.summary()

                # ‡∏Ñ‡∏≠‡∏°‡πÑ‡∏û‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•
                model.compile(
                    loss='categorical_crossentropy',
                    optimizer='SGD',
                    metrics=['accuracy']
                )
            """)

        st.markdown("---")
        st.subheader("üéâüéâüéâ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û")

    def cnn_model_training(self):
        st.header("üåü ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model CNN")
        st.markdown("---")
        st.subheader("ü™õCode ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model CNN")
        st.markdown("---")
        st.subheader("üñ•Ô∏è‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•")
        st.code("""
                # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô epoch ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
                epochs = 30

                # ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
                history = model.fit(
                    train_generator,
                    epochs=epochs,
                    validation_data=test_generator,
                    verbose=1
                )

                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
                model.save('../exported_models/cnn/fruit_classifier_model.h5')
                
                # Output ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
                # Epoch 1/30
                # 72/72 [==============================] - 111s 2s/step - loss: 2.2900 - accuracy: 0.1156 - val_loss: 2.2474 - val_accuracy: 0.1668
                # Epoch 2/30
                # 72/72 [==============================] - 115s 2s/step - loss: 2.2109 - accuracy: 0.1678 - val_loss: 2.1626 - val_accuracy: 0.2000
                # ...
                # Epoch 30/30
                # 72/72 [==============================] - 98s 1s/step - loss: 0.2845 - accuracy: 0.9124 - val_loss: 0.3574 - val_accuracy: 0.8932
        """)

        st.subheader("üñ•Ô∏è‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô")
        st.code("""
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
                plt.figure(figsize=(12, 4))
                
                # ‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á Accuracy
                plt.subplot(1, 2, 1)
                plt.plot(history.history['accuracy'], label='Train Accuracy')
                plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
                plt.xlabel('Epoch')
                plt.ylabel('Accuracy')
                plt.legend()
                plt.title('Model Accuracy')
                
                # ‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á Loss
                plt.subplot(1, 2, 2)
                plt.plot(history.history['loss'], label='Train Loss')
                plt.plot(history.history['val_loss'], label='Validation Loss')
                plt.xlabel('Epoch')
                plt.ylabel('Loss')
                plt.legend()
                plt.title('Model Loss')
                
                plt.tight_layout()
                plt.show()
        """)

        st.subheader("üñ•Ô∏è‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÇ‡∏°‡πÄ‡∏î‡∏•")
        st.code("""
                # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏±‡∏ö‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö
                test_loss, test_acc = model.evaluate(test_generator)
                print(f"‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö: {test_acc:.4f}")
                print(f"‡∏Ñ‡πà‡∏≤ loss ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö: {test_loss:.4f}")
                
                # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏ö‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö
                predictions = model.predict(test_generator)
                predicted_classes = np.argmax(predictions, axis=1)
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì confusion matrix
                from sklearn.metrics import confusion_matrix, classification_report
                
                # ‡πÉ‡∏ä‡πâ generator.classes ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á label ‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á
                true_classes = test_generator.classes[:len(predicted_classes)]
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á confusion matrix
                cm = confusion_matrix(true_classes, predicted_classes)
                
                # ‡πÅ‡∏™‡∏î‡∏á confusion matrix ‡∏î‡πâ‡∏ß‡∏¢ seaborn
                plt.figure(figsize=(10, 8))
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                           xticklabels=list(class_names.values()),
                           yticklabels=list(class_names.values()))
                plt.xlabel('Predicted')
                plt.ylabel('True')
                plt.title('Confusion Matrix')
                plt.show()
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
                print("Classification Report:")
                print(classification_report(true_classes, predicted_classes, 
                                          target_names=list(class_names.values())))
        """)

        st.subheader("üéâüéâüéâ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model CNN")

    def load_model(self):
        st.header("üåü ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Model CNN ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        st.markdown("---")
        st.subheader("üñ•Ô∏èCode ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Model CNN")
        st.code("""
                import tensorflow as tf
                import numpy as np
                from tensorflow.keras.preprocessing.image import load_img, img_to_array
                import os
                
                def load_cnn_model(model_path):
                    try:
                        model = tf.keras.models.load_model(model_path)
                        return model
                    except Exception as e:
                        st.error(f"Error loading model: {str(e)}")
                        return None
                
                # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
                model = load_cnn_model('../exported_models/cnn/fruit_classifier_model.h5')
                
                # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
                def predict_image(model, img_path, target_size=(224, 224)):
                    # ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î
                    img = load_img(img_path, target_size=target_size)
                    
                    # ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô array ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•
                    img_array = img_to_array(img) / 255.0
                    
                    # ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏°‡∏¥‡∏ï‡∏¥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö input ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
                    img_array = np.expand_dims(img_array, axis=0)
                    
                    # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
                    prediction = model.predict(img_array)
                    
                    # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™
                    predicted_class = np.argmax(prediction, axis=1)[0]
                    confidence = np.max(prediction) * 100
                    
                    return predicted_class, confidence, prediction[0]
                """)

        st.markdown("---")
        st.subheader("‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•")
        st.code("""
                class Neuron_implement_viewset:
                    def __init__(self):
                        # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
                        self.cnn_model = load_cnn_model("exported_models/cnn/fruit_classifier_model.h5")
                        
                        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™
                        self.class_names = {
                            0: "Apple", 1: "Banana", 2: "Grape", 3: "Kiwi", 4: "Mango",
                            5: "Orange", 6: "Peach", 7: "Pineapple", 8: "Strawberry", 9: "Watermelon"
                        }
                    
                    def predict(self, image_path):
                        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
                        predicted_class, confidence, all_probs = predict_image(
                            self.cnn_model, image_path, target_size=(224, 224)
                        )
                        
                        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡πÑ‡∏°‡πâ
                        fruit_name = self.class_names[predicted_class]
                        
                        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                        result = {
                            "fruit_name": fruit_name,
                            "confidence": f"{confidence:.2f}%",
                            "all_probabilities": {self.class_names[i]: f"{prob*100:.2f}%" for i, prob in enumerate(all_probs)}
                        }
                        
                        return result
                """)

        st.subheader("üéâüéâüéâ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Model CNN ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        st.markdown("---")
